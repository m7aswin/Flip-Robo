{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”\n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('D:\\Data Science\\Web Scraping\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the skill input filed using name attribute\n",
    "inp_skills=driver.find_element_by_name('keyword')\n",
    "inp_skills.clear()\n",
    "inp_skills.send_keys('Data Analyst')\n",
    "\n",
    "# Finding the location input filed using name attribute\n",
    "inp_loc=driver.find_element_by_name('location')\n",
    "inp_loc.clear()\n",
    "inp_loc.send_keys('Bangalore')\n",
    "\n",
    "#finding the search botton using class attribute\n",
    "submit_btn=driver.find_element_by_class_name('btn')\n",
    "submit_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=[]\n",
    "locs=[]\n",
    "cnames=[]\n",
    "exps=[]\n",
    "\n",
    "# extractiong Job titles\n",
    "for title in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')[:10]:\n",
    "    titles.append(title.text)\n",
    "    \n",
    "# extractiong Company name\n",
    "for cname in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')[:10]:\n",
    "    cnames.append(cname.text)\n",
    "\n",
    "#extracting locations\n",
    "for loc,n in zip(driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')[2::3],range(10)):\n",
    "    locs.append(loc.text)\n",
    "\n",
    "#extractiong experience    \n",
    "for exp,n in zip(driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')[::3],range(10)):\n",
    "    exps.append(exp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(titles),len(locs),len(cnames),len(exps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DA_df=pd.DataFrame({'Job Title':titles,'Location':locs,\n",
    "             'Company Name':cnames,'Experience':exps})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring Data Analysts For E commerce Platform |...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Allegis Services India Pvt. Ltd.</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DA - Urgent Opening For Data Analyst BFSI Doma...</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Tata Consultancy Services Ltd.</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell India Markets Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Assistant Vice President - MIS &amp; Reporting ( B...</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Myntra Designs Pvt. Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1                                       Data Analyst   \n",
       "2  Hiring Data Analysts For E commerce Platform |...   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5  DA - Urgent Opening For Data Analyst BFSI Doma...   \n",
       "6                                       Data Analyst   \n",
       "7  Assistant Vice President - MIS & Reporting ( B...   \n",
       "8                                       Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                        Mumbai, Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                        Company Name Experience  \n",
       "0                 Inflexion Analytix Private Limited    0-3 Yrs  \n",
       "1            GlaxoSmithKline Pharmaceuticals Limited    0-2 Yrs  \n",
       "2                   Allegis Services India Pvt. Ltd.    0-5 Yrs  \n",
       "3                Shell India Markets Private Limited    5-8 Yrs  \n",
       "4                                  Applied Materials   7-10 Yrs  \n",
       "5                     Tata Consultancy Services Ltd.    4-9 Yrs  \n",
       "6                Shell India Markets Private Limited    5-8 Yrs  \n",
       "7  INTERTRUSTVITEOS CORPORATE AND FUND SERVICES P...  12-18 Yrs  \n",
       "8                           Myntra Designs Pvt. Ltd.    3-6 Yrs  \n",
       "9                           Myntra Designs Pvt. Ltd.    3-6 Yrs  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DA_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter\n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('D:\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the skill input filed using name attribute\n",
    "inp_skills=driver.find_element_by_name('keyword')\n",
    "inp_skills.clear()\n",
    "inp_skills.send_keys('Data Scientist')\n",
    "\n",
    "# Finding the location input filed using name attribute\n",
    "inp_loc=driver.find_element_by_name('location')\n",
    "inp_loc.clear()\n",
    "inp_loc.send_keys('Bangalore')\n",
    "\n",
    "#finding the search botton using class attribute\n",
    "submit_btn=driver.find_element_by_class_name('btn')\n",
    "submit_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_urls=driver.current_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(ds_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=[]\n",
    "locs=[]\n",
    "cnames=[]\n",
    "exps=[]\n",
    "\n",
    "# extractiong Job titles\n",
    "for title in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')[:10]:\n",
    "    titles.append(title.text)\n",
    "    \n",
    "# extractiong Company name\n",
    "for cname in driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')[:10]:\n",
    "    cnames.append(cname.text)\n",
    "\n",
    "#extracting locations\n",
    "for loc,n in zip(driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')[2::3],range(10)):\n",
    "    locs.append(loc.text)\n",
    "\n",
    "#extractiong experience    \n",
    "for exp,n in zip(driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')[::3],range(10)):\n",
    "    exps.append(exp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction job description\n",
    "urls=[]\n",
    "for x in driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')[:10]:\n",
    "    urls.append(x.get_attribute('href'))\n",
    "\n",
    "despts=[]\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(0.8)\n",
    "    try:\n",
    "        despts.append(driver.find_element_by_xpath('//div[@class=\"dang-inner-html\"]').text)\n",
    "    except:\n",
    "        despts.append(driver.find_element_by_xpath('//div[@class=\"clearboth description\"]').text)\n",
    "    driver.get(ds_urls)\n",
    "    time.sleep(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(despts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_df=pd.DataFrame({'Job Title':titles,'Location':locs,\n",
    "             'Company Name':cnames,'Experience':exps,'Description':despts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Job Role : Data Scientist/Data Analyst /Busine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Roles and Responsibilities\\n\\nMandatory Skills...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Roles and Responsibilities\\n\\nMandatory Skills...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analytics &amp; AI Product Mgmt - Sr. Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GlaxoSmithKline Pharmaceuticals Limited</td>\n",
       "      <td>10-12 Yrs</td>\n",
       "      <td>Given the increased focus on data and analytic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Pune, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Vijaya Management Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>.\\nRoles and Responsibilities\\nAnalyze structu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist, Modeling</td>\n",
       "      <td>Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...</td>\n",
       "      <td>Nielsen</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>We wont say we can predict the future, but our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - IBM Garage</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>As a Data Scientist in the IBM Garage team you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Introduction\\nAs a Data Scientist at IBM, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Introduction\\nAs a Data Scientist at IBM, you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist - Credit risk</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Scienaptic Systems</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Responsibilities and duties Focus on developin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "2  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "3   Analytics & AI Product Mgmt - Sr. Data Scientist   \n",
       "4                              Senior Data Scientist   \n",
       "5                    Senior Data Scientist, Modeling   \n",
       "6                        Data Scientist - IBM Garage   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                Senior Data Scientist - Credit risk   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "1  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "2  Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                 Pune, Chennai, Bangalore/Bengaluru   \n",
       "5  Kolkata, Gurgaon/Gurugram, Bangalore/Bengaluru...   \n",
       "6  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "7  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "8  Noida, Hyderabad/Secunderabad, Bangalore/Benga...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                              Company Name Experience  \\\n",
       "0       Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "1                                 CES Ltd.    2-7 Yrs   \n",
       "2                                 CES Ltd.    2-7 Yrs   \n",
       "3  GlaxoSmithKline Pharmaceuticals Limited  10-12 Yrs   \n",
       "4               Vijaya Management Services   5-10 Yrs   \n",
       "5                                  Nielsen    3-7 Yrs   \n",
       "6                   IBM India Pvt. Limited    5-8 Yrs   \n",
       "7                   IBM India Pvt. Limited    4-9 Yrs   \n",
       "8                   IBM India Pvt. Limited    5-8 Yrs   \n",
       "9                       Scienaptic Systems   5-10 Yrs   \n",
       "\n",
       "                                         Description  \n",
       "0  Job Role : Data Scientist/Data Analyst /Busine...  \n",
       "1  Roles and Responsibilities\\n\\nMandatory Skills...  \n",
       "2  Roles and Responsibilities\\n\\nMandatory Skills...  \n",
       "3  Given the increased focus on data and analytic...  \n",
       "4  .\\nRoles and Responsibilities\\nAnalyze structu...  \n",
       "5  We wont say we can predict the future, but our...  \n",
       "6  As a Data Scientist in the IBM Garage team you...  \n",
       "7  Introduction\\nAs a Data Scientist at IBM, you ...  \n",
       "8  Introduction\\nAs a Data Scientist at IBM, you ...  \n",
       "9  Responsibilities and duties Focus on developin...  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this question you have to scrape data using the filters available on the\n",
    "webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "\n",
    "You have to scrape the job-title, job-location,      company_name,experience_required.\n",
    "\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "\n",
    "The task will be done as shown in the below steps:\n",
    "\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('D:\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the skill input filed using name attribute\n",
    "inp_skills=driver.find_element_by_name('keyword')\n",
    "inp_skills.clear()\n",
    "inp_skills.send_keys('Data Scientist')\n",
    "\n",
    "#finding the search botton using class attribute\n",
    "btn=driver.find_element_by_class_name('search-btn')\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking location filter Delhi/NCR\n",
    "driver.find_element_by_xpath('/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/i').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking salary filter 3-6 Lakhs\n",
    "driver.find_element_by_xpath('//*[@id=\"root\"]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/i').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping job title\n",
    "titles=[]\n",
    "for x in driver.find_elements_by_xpath('//div[@class=\"info fleft\"]/a')[:10]:\n",
    "    titles.append(x.text.replace('\\n',''))\n",
    "    \n",
    " # Scraping Companies   \n",
    "companies=[]\n",
    "for x in driver.find_elements_by_xpath('//div[@class=\"mt-7 companyInfo subheading lh16\"]/a[@class=\"subTitle ellipsis fleft\"]')[:10]:\n",
    "    companies.append(x.text.replace('\\n',''))\n",
    "    \n",
    "# Scraping Experience    \n",
    "exps=[]\n",
    "for x in driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')[0::3][:10]:\n",
    "    exps.append(x.text.replace('\\n',''))\n",
    "    \n",
    "# Scraping locations        \n",
    "locs=[]\n",
    "for x in driver.find_elements_by_xpath('//span[@class=\"ellipsis fleft fs12 lh16\"]')[2::3][:10]:\n",
    "    locs.append(x.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - High growth VC backed Influen...</td>\n",
       "      <td>Ravgins International Pvt. Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Excellent opportunity For Data Scientist</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mobikwik</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>New Delhi, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DATA Scientist – Gurgaon (Exp 3-6 years)</td>\n",
       "      <td>CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - Noida</td>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Noida/ B'lore</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Bangalore/Benga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Cloudstrats Technologies Private Limited</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst   \n",
       "1  Data Scientist - High growth VC backed Influen...   \n",
       "2           Excellent opportunity For Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "5           DATA Scientist – Gurgaon (Exp 3-6 years)   \n",
       "6                             Data Scientist - Noida   \n",
       "7                     Data Scientist - Noida/ B'lore   \n",
       "8                                     Data Scientist   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                             Company Experience  \\\n",
       "0                 Inflexion Analytix Private Limited    0-3 Yrs   \n",
       "1                    Ravgins International Pvt. Ltd.    3-5 Yrs   \n",
       "2              NEC CORPORATION INDIA PRIVATE LIMITED    3-7 Yrs   \n",
       "3                                           Mobikwik    3-5 Yrs   \n",
       "4  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...    3-6 Yrs   \n",
       "5  CRESCENDO GLOBAL LEADERSHIP HIRING INDIA PRIVA...    3-6 Yrs   \n",
       "6     Optum Global Solutions (India) Private Limited    3-5 Yrs   \n",
       "7              NEC CORPORATION INDIA PRIVATE LIMITED    3-8 Yrs   \n",
       "8                             IBM India Pvt. Limited    4-9 Yrs   \n",
       "9           Cloudstrats Technologies Private Limited    5-8 Yrs   \n",
       "\n",
       "                                            Location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "2                         Noida, Bangalore/Bengaluru  \n",
       "3           New Delhi, Gurgaon/Gurugram, Delhi / NCR  \n",
       "4                      Gurgaon/Gurugram, Delhi / NCR  \n",
       "5                      Gurgaon/Gurugram, Delhi / NCR  \n",
       "6                                              Noida  \n",
       "7                         Noida, Bangalore/Bengaluru  \n",
       "8  Noida, Hyderabad/Secunderabad, Bangalore/Benga...  \n",
       "9  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  "
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company_df=pd.DataFrame({'Title':titles,'Company':companies,'Experience':exps,'Location':locs})\n",
    "Company_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company.\n",
    "\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2. Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3. Then click the search button. You will land up in the below page:\n",
    "4. Then scrape the data for the first 10 jobs results you get in the above shown page.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('D:\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.glassdoor.co.in/index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('/html/body/div[2]/div/div/div/div/div[1]/article/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_title=driver.find_element_by_name('sc.keyword')\n",
    "inp_title.clear()\n",
    "inp_title.send_keys('Data Scientist')\n",
    "\n",
    "inp_loc=driver.find_element_by_xpath('/html/body/header/nav/div[2]/div/div/div[2]/form/div/div[3]/div/input')\n",
    "inp_loc.clear()\n",
    "inp_loc.send_keys('Noida')\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/header/nav/div[2]/div/div/div[2]/form/div/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping company names\n",
    "cnames=[]\n",
    "for x in driver.find_elements_by_xpath('//div[@class=\"d-flex justify-content-between align-items-start\"]/a[@class=\" css-l2wjgv e1n63ojh0 jobLink\"]')[:10]:\n",
    "    cnames.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping Rating\n",
    "ratings=[]\n",
    "for x in driver.find_elements_by_xpath('//div[@class=\"d-flex flex-column css-x75kgh e1rrn5ka3\"]/span')[:10]:\n",
    "    ratings.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping number of days job posted\n",
    "nodays=[]\n",
    "for x in driver.find_elements_by_xpath('//div[@class=\"d-flex align-items-end pl-std css-mi55ob\"]')[:10]:\n",
    "    nodays.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Raing</th>\n",
       "      <th>No Days Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bechtel</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mansha Solutions</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MasterCard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lantern Digital Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name Raing No Days Posted\n",
       "0                   Bechtel   4.0            13d\n",
       "1          Mansha Solutions   NaN             5d\n",
       "2                MasterCard   NaN            18d\n",
       "3  Lantern Digital Services   NaN             4d\n",
       "4                  Ericsson   NaN            NaN\n",
       "5                       NaN   NaN            NaN\n",
       "6                       NaN   NaN            NaN\n",
       "7                       NaN   NaN            NaN\n",
       "8                       NaN   NaN            NaN\n",
       "9                       NaN   NaN            NaN"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company_data=pd.DataFrame({'Company Name':cnames,'Raing':ratings,'No Days Posted':nodays}).replace('',np.NAN)\n",
    "Company_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape the salary data for Data Scientist designation\n",
    "in Noida location.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Min\n",
    "salary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2. Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3. Click the search button.\n",
    "4. After that you will land on the below page You have to scrape whole data from this webpage\n",
    "5. Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company.\n",
    "6. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('D:\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.glassdoor.co.in/Salaries/index.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_title=driver.find_element_by_xpath('//*[@id=\"KeywordSearch\"]')\n",
    "inp_title.clear()\n",
    "inp_title.send_keys('Data Scientist')\n",
    "\n",
    "inp_loc=driver.find_element_by_xpath('/html/body/div[3]/div/div[1]/div[1]/div/div/form/input[6]')\n",
    "inp_loc.clear()\n",
    "inp_loc.send_keys('Noida')\n",
    "\n",
    "driver.find_element_by_xpath('//*[@id=\"HeroSearchButton\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames=[]\n",
    "for x in driver.find_elements_by_xpath('//p[@class=\"m-0 \"]')[:10]:\n",
    "    cnames.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgsals=[]\n",
    "for x in driver.find_elements_by_xpath('//p[@class=\"d-block d-md-none m-0\"]')[:10]:\n",
    "    avgsals.append(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "minsals=[]\n",
    "maxsals=[]\n",
    "for x in driver.find_elements_by_xpath('//p[@class=\"d-block d-md-none m-0 css-1kuy7z7\"]')[:10]:\n",
    "    st=re.findall('\\d+',x.text)\n",
    "    if len(st)==3:\n",
    "        minsal=float(st[0])*1000\n",
    "        maxsal=float(st[1]+st[2])*1000\n",
    "    elif len(st)==4:\n",
    "        minsal=float(st[0]+st[1])*1000\n",
    "        maxsal=float(st[2]+st[3])*1000\n",
    "    else:\n",
    "        continue\n",
    "    minsals.append(minsal)\n",
    "    maxsals.append(maxsal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Average Salary</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tata Consultancy Services</td>\n",
       "      <td>₹ 6,11,228/yr</td>\n",
       "      <td>343000.0</td>\n",
       "      <td>1095000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>₹ 11,46,533/yr</td>\n",
       "      <td>577000.0</td>\n",
       "      <td>2213000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>₹ 8,97,795/yr</td>\n",
       "      <td>586000.0</td>\n",
       "      <td>2730000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ericsson-Worldwide</td>\n",
       "      <td>₹ 7,38,057/yr</td>\n",
       "      <td>355000.0</td>\n",
       "      <td>1613000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhivery</td>\n",
       "      <td>₹ 12,39,781/yr</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>11622000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>₹ 13,36,142/yr</td>\n",
       "      <td>1069000.0</td>\n",
       "      <td>1520000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Valiance Solutions</td>\n",
       "      <td>₹ 8,15,192/yr</td>\n",
       "      <td>502000.0</td>\n",
       "      <td>1465000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>₹ 11,35,221/yr</td>\n",
       "      <td>202000.0</td>\n",
       "      <td>1809000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EXL Service</td>\n",
       "      <td>₹ 11,44,243/yr</td>\n",
       "      <td>575000.0</td>\n",
       "      <td>1520000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optum Global Solutions</td>\n",
       "      <td>₹ 14,13,288/yr</td>\n",
       "      <td>1014000.0</td>\n",
       "      <td>2149000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Company  Average Salary  Minimum Salary  Maximum Salary\n",
       "0  Tata Consultancy Services   ₹ 6,11,228/yr        343000.0       1095000.0\n",
       "1                  Accenture  ₹ 11,46,533/yr        577000.0       2213000.0\n",
       "2                        IBM   ₹ 8,97,795/yr        586000.0       2730000.0\n",
       "3         Ericsson-Worldwide   ₹ 7,38,057/yr        355000.0       1613000.0\n",
       "4                  Delhivery  ₹ 12,39,781/yr        450000.0      11622000.0\n",
       "5         UnitedHealth Group  ₹ 13,36,142/yr       1069000.0       1520000.0\n",
       "6         Valiance Solutions   ₹ 8,15,192/yr        502000.0       1465000.0\n",
       "7              ZS Associates  ₹ 11,35,221/yr        202000.0       1809000.0\n",
       "8                EXL Service  ₹ 11,44,243/yr        575000.0       1520000.0\n",
       "9     Optum Global Solutions  ₹ 14,13,288/yr       1014000.0       2149000.0"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Glassdoor_df=pd.DataFrame({'Company':cnames,'Average Salary':avgsals,'Minimum Salary':minsals,'Maximum Salary':maxsals})\n",
    "Glassdoor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes: Brand, Product Description, Price, Discount %\n",
    "\n",
    "1. Go to flipkart webpage by url https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "3. after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it\n",
    "5. Now scrape data from this page as usual\n",
    "6. repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('D:\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div/button').click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_cat=driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "inp_cat.clear()\n",
    "inp_cat.send_keys('Sunglasses')\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appends():\n",
    "    for x in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "        brands.append(x.text.replace('\\n',''))\n",
    "    \n",
    "    for x in driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]'):\n",
    "        details.append(x.text.replace('\\n',''))\n",
    "    \n",
    "    for x in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "        prices.append(x.text.replace('\\n',''))\n",
    "    \n",
    "    for x in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]'):\n",
    "        disnts.append(x.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nextpage():\n",
    "    try:\n",
    "        next_page=driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "        next_page.click()\n",
    "        \n",
    "    except:\n",
    "        driver.find_element_by_xpath('/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=[]\n",
    "details=[]\n",
    "prices=[]\n",
    "disnts=[]\n",
    "while len(brands)<=100:\n",
    "    appends()        \n",
    "    \n",
    "    driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]')\n",
    "    time.sleep(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Gradient Round, Shield Sunglass...</td>\n",
       "      <td>₹395</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>like future</td>\n",
       "      <td>UV Protection, Polarized, Gradient, Mirrored W...</td>\n",
       "      <td>₹284</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹758</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹630</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PHENOMENAL</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ray-Ban</td>\n",
       "      <td>Mirrored Round Sunglasses (51)</td>\n",
       "      <td>₹8,607</td>\n",
       "      <td>15% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection, Mirrored Aviator Sunglasses (58)</td>\n",
       "      <td>₹606</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>FLYING MACHINE</td>\n",
       "      <td>UV Protection, Gradient Aviator Sunglasses (52)</td>\n",
       "      <td>₹508</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>FOSSIL</td>\n",
       "      <td>Gradient, Mirrored, UV Protection, Polarized R...</td>\n",
       "      <td>₹2,739</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>Gradient Round Sunglasses (Free Size)</td>\n",
       "      <td>₹419</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Brands                                            Product   Price  \\\n",
       "0           AISLIN  UV Protection, Gradient Round, Shield Sunglass...    ₹395   \n",
       "1      like future  UV Protection, Polarized, Gradient, Mirrored W...    ₹284   \n",
       "2         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)    ₹758   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)    ₹630   \n",
       "4       PHENOMENAL  UV Protection Retro Square Sunglasses (Free Size)    ₹399   \n",
       "..             ...                                                ...     ...   \n",
       "95         Ray-Ban                     Mirrored Round Sunglasses (51)  ₹8,607   \n",
       "96          AISLIN    UV Protection, Mirrored Aviator Sunglasses (58)    ₹606   \n",
       "97  FLYING MACHINE    UV Protection, Gradient Aviator Sunglasses (52)    ₹508   \n",
       "98          FOSSIL  Gradient, Mirrored, UV Protection, Polarized R...  ₹2,739   \n",
       "99           NuVew              Gradient Round Sunglasses (Free Size)    ₹419   \n",
       "\n",
       "   Discount  \n",
       "0   77% off  \n",
       "1   71% off  \n",
       "2   15% off  \n",
       "3   21% off  \n",
       "4   80% off  \n",
       "..      ...  \n",
       "95  15% off  \n",
       "96  75% off  \n",
       "97  57% off  \n",
       "98  37% off  \n",
       "99  66% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flipkart_df=pd.DataFrame({'Brands':brands[:100],'Product':details[:100],'Price':prices[:100],'Discount':disnts[:100]})\n",
    "Flipkart_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('D:\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver.find_element_by_xpath('/html/body/div[2]/div/div/button').click()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_cat=driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "inp_cat.clear()\n",
    "inp_cat.send_keys('Sneakers')\n",
    "\n",
    "driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appends():\n",
    "    for x in driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]'):\n",
    "        brands.append(x.text.replace('\\n',''))\n",
    "    \n",
    "    for x in driver.find_elements_by_xpath('//a[@class=\"IRpwTa _2-ICcC\"]'):\n",
    "        details.append(x.text.replace('\\n',''))\n",
    "    \n",
    "    for x in driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]'):\n",
    "        prices.append(x.text.replace('\\n',''))\n",
    "    \n",
    "    for x in driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]'):\n",
    "        disnts.append(x.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=[]\n",
    "details=[]\n",
    "prices=[]\n",
    "disnts=[]\n",
    "while len(brands)<=100:\n",
    "    appends()        \n",
    "    \n",
    "    driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]').click()\n",
    "    time.sleep(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 31 120 119\n"
     ]
    }
   ],
   "source": [
    "print(len(brands),len(details),len(prices),len(disnts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brands</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aadi</td>\n",
       "      <td>₹298</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOTSTYLE</td>\n",
       "      <td>₹283</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Birde</td>\n",
       "      <td>₹698</td>\n",
       "      <td>43% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>₹3,931</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Qtsy</td>\n",
       "      <td>₹249</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>well feet</td>\n",
       "      <td>₹375</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VISTAARA</td>\n",
       "      <td>₹251</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Brands   Price Discount\n",
       "0   Robbie jones    ₹399  60% off\n",
       "1           aadi    ₹298  70% off\n",
       "2        Numenzo    ₹398  60% off\n",
       "3       HOTSTYLE    ₹283  43% off\n",
       "4   Robbie jones    ₹474  52% off\n",
       "..           ...     ...      ...\n",
       "95         Birde    ₹698  43% off\n",
       "96          PUMA  ₹3,931  50% off\n",
       "97          Qtsy    ₹249  62% off\n",
       "98     well feet    ₹375  74% off\n",
       "99      VISTAARA    ₹251  50% off\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Flikart_Sneakers=pd.DataFrame({'Brands':brands[:100],'Price':prices[:100],'Discount':disnts[:100]})\n",
    "Flikart_Sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faux Leather Casual Shoes White Colour | New Sneakers s...\n",
      "jeans casual sneakers for cool look denim shoes (blue) ...\n",
      "EVAW2 Sneakers For Men\n",
      "casual , Partywear Sneakers , Denim Sneakers For Men , ...\n",
      "Sneakers For Men\n",
      "Sneakers For Men\n",
      "Casual Sneakers Sneakers For Men\n",
      "Sneakers For Men\n",
      "Rockstyle Trending Multicolor Ultralight canvas Sport/ ...\n",
      "men sneakers Sneakers For Men\n",
      "Sneakers For Men\n",
      "Street Smart Sneakers For Men\n"
     ]
    }
   ],
   "source": [
    "for x in driver.find_elements_by_xpath('//div[@class=\"_2B099V\"]/a[@class=\"IRpwTa _2-ICcC\"]'):\n",
    "        print(x.text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product details have different class names, so its difficult to scrap product details for this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to\n",
    "go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace.\n",
    "\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('D:\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving to review page\n",
    "driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appends():\n",
    "    for x in driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]'):\n",
    "        ratings.append(x.text)\n",
    "        \n",
    "    for x in driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]'):\n",
    "        comments.append(x.text)\n",
    "        \n",
    "    for x in driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]'):\n",
    "        reviews.append(x.text.replace('\\n',''))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=[]\n",
    "comments=[]\n",
    "reviews=[]\n",
    "while len(comments)<=100:\n",
    "    appends()        \n",
    "    \n",
    "    driver.find_element_by_xpath('//*[@id=\"container\"]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[11]').click()\n",
    "    time.sleep(.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Comments</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the MoneyThe iPhone 11 offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.I’m am ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Really Awesome</td>\n",
       "      <td>Apple products though quite expensive still ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Awesome Device thanks aapplee for this great d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Slightly disappointed</td>\n",
       "      <td>Most disappointing aspect is that Apple in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>buy this product u will never regret... feel h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>2nd iPhone after iPhone 6 and upgrade from Goo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings               Comments  \\\n",
       "0        5              Brilliant   \n",
       "1        5       Perfect product!   \n",
       "2        5          Great product   \n",
       "3        5      Worth every penny   \n",
       "4        4            Good choice   \n",
       "..     ...                    ...   \n",
       "95       5         Really Awesome   \n",
       "96       5    Best in the market!   \n",
       "97       5  Slightly disappointed   \n",
       "98       4              Just wow!   \n",
       "99       5  Mind-blowing purchase   \n",
       "\n",
       "                                               Review  \n",
       "0   The Best Phone for the MoneyThe iPhone 11 offe...  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Amazing Powerful and Durable Gadget.I’m am ver...  \n",
       "3   Previously I was using one plus 3t it was a gr...  \n",
       "4   So far it’s been an AMAZING experience coming ...  \n",
       "..                                                ...  \n",
       "95  Apple products though quite expensive still ke...  \n",
       "96  Awesome Device thanks aapplee for this great d...  \n",
       "97  Most disappointing aspect is that Apple in the...  \n",
       "98  buy this product u will never regret... feel h...  \n",
       "99  2nd iPhone after iPhone 6 and upgrade from Goo...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Iphone_df=pd.DataFrame({'Ratings':ratings[:100],'Comments':comments[:100],'Review':reviews[:100]})\n",
    "Iphone_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, as shown in\n",
    "the below image\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of\n",
    "the shoes , Short Shoe description, price of the shoe as shown in the below image.\n",
    "Please note that applying the filter and scraping the data , everything should be\n",
    "done through code only and there should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('D:\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting price filter\n",
    "driver.find_element_by_xpath('//*[@id=\"mountRoot\"]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/input').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to webpage https://www.amazon.in/\n",
    " Enter “Laptop” in the search field and then click the search icon.\n",
    " Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the\n",
    "below image:\n",
    "    \n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('D:\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
