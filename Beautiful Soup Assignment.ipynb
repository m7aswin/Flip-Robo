{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to display all the header tags from\n",
    "‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_link='https://en.wikipedia.org/wiki/Main_Page'\n",
    "tag='h2'\n",
    "tags=['h1','h2','h3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscraping(link,tag):\n",
    "    wiki_page=requests.get(link)\n",
    "    \n",
    "    wiki=BeautifulSoup(wiki_page.content)\n",
    "    \n",
    "    titles=wiki.find_all(tag)\n",
    "    \n",
    "    headings=[]\n",
    "    for title in titles:\n",
    "        headings.append(title.text.replace('\\n',''))\n",
    "    \n",
    "    return headings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Headings in h2 tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages',\n",
       " 'Navigation menu']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webscraping(wiki_link,tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heading in h1,h2, and h3 tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Main Page',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages',\n",
       " 'Navigation menu',\n",
       " 'Personal tools',\n",
       " 'Namespaces',\n",
       " 'Variants',\n",
       " 'Views',\n",
       " 'More',\n",
       " 'Search',\n",
       " 'Navigation',\n",
       " 'Contribute',\n",
       " 'Tools',\n",
       " 'Print/export',\n",
       " 'In other projects',\n",
       " 'Languages']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webscraping(wiki_link,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Headings':webscraping(wiki_link,tags)}).to_csv('Heading.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name,\n",
    "IMDB rating, Year of release) and save it in form of a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_link='https://www.imdb.com/chart/top/?ref_=nv_mv_250'\n",
    "tag='td'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscraping_imdb(link,tag):\n",
    "    imdb_page=requests.get(link)\n",
    "    imdb=BeautifulSoup(imdb_page.content)\n",
    "    \n",
    "    names=[]\n",
    "    years=[]\n",
    "    for x in imdb.find_all(tag,class_='titleColumn')[:100]:\n",
    "        names.append(x.find('a').text)\n",
    "        years.append(re.sub('[()]','',x.find('span').text))\n",
    "        \n",
    "    ratings=[]\n",
    "    for x in imdb.find_all('td',class_='ratingColumn imdbRating')[:100]:\n",
    "        ratings.append(x.text.replace('\\n',''))\n",
    "        \n",
    "    df=pd.DataFrame({'Movie':names,'Rating':ratings,'Year_of_Release':years,})\n",
    "    print(df)\n",
    "    df.to_csv('imdb_top100movies.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Movie Rating Year_of_Release\n",
      "0                The Shawshank Redemption    9.2            1994\n",
      "1                           The Godfather    9.1            1972\n",
      "2                  The Godfather: Part II    9.0            1974\n",
      "3                         The Dark Knight    9.0            2008\n",
      "4                            12 Angry Men    8.9            1957\n",
      "..                                    ...    ...             ...\n",
      "95                     North by Northwest    8.3            1959\n",
      "96                    Singin' in the Rain    8.3            1952\n",
      "97  Eternal Sunshine of the Spotless Mind    8.3            2004\n",
      "98                    Ladri di biciclette    8.3            1948\n",
      "99                           Idi i smotri    8.3            1985\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "webscraping_imdb(imdb_link,tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e.\n",
    "Name, IMDB rating, Year of release) and save it in form of a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ind_link='https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=8a7876cd-2844-4017-846a-2c0876945b7b&pf_rd_r=QA4JGCD0VVTMXZ85RHJ8&pf_rd_s=right-5&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_india_tr_rhs_1'\n",
    "tag='td'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webscraping_imdb_ind(link,tag):\n",
    "    imdb_ind_page=requests.get(link)\n",
    "    imdb_ind=BeautifulSoup(imdb_ind_page.content)\n",
    "    \n",
    "    names=[]\n",
    "    years=[]\n",
    "    for x in imdb_ind.find_all(tag,class_='titleColumn')[:100]:\n",
    "        names.append(x.find('a').text)\n",
    "        years.append(re.sub('[()]','',x.find('span').text))\n",
    "        \n",
    "    ratings=[]\n",
    "    for x in imdb_ind.find_all('td',class_='ratingColumn imdbRating')[:100]:\n",
    "        ratings.append(x.text.replace('\\n',''))\n",
    "        \n",
    "    df=pd.DataFrame({'Movie':names,'Rating':ratings,'Year_of_Release':years,})\n",
    "    print(df)\n",
    "    df.to_csv('imdb_ind_top100movies.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Movie Rating Year_of_Release\n",
      "0              Pather Panchali    8.5            1955\n",
      "1                      Nayakan    8.5            1987\n",
      "2                     Gol Maal    8.5            1979\n",
      "3                   Anbe Sivam    8.5            2003\n",
      "4                  Apur Sansar    8.5            1959\n",
      "..                         ...    ...             ...\n",
      "95                       Iqbal    8.1            2005\n",
      "96                  Chhichhore    8.1            2019\n",
      "97                       Lucia    8.0            2013\n",
      "98                  Bommarillu    8.0            2006\n",
      "99  The Legend of Bhagat Singh    8.0            2002\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "webscraping_imdb_ind(imdb_ind_link,tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrap book name, author name, genre and book review of\n",
    "any 5 books from ‘www.bookpage.com’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_link='https://bookpage.com/reviews'\n",
    "tags=['h4','p','p','div']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bookpage_scraping(link,tags):\n",
    "    bk_page=requests.get(link)\n",
    "    bk=BeautifulSoup(bk_page.content)\n",
    "    driver=webdriver.Chrome(executable_path='D:\\chromedriver.exe')\n",
    "    driver.get(link)\n",
    "    itag=iter(tags)\n",
    "    \n",
    "    tag=next(itag)\n",
    "    bk_titles=[]\n",
    "    for x in bk.find_all(tag,class_='italic')[:5]:\n",
    "        bk_titles.append(x.text.replace('\\n',''))\n",
    "        \n",
    "    tag=next(itag)    \n",
    "    bk_authors=[]\n",
    "    for x in bk.find_all(tag,class_='sans bold')[:5]:\n",
    "        bk_authors.append(x.text.replace('\\n',''))\n",
    "    \n",
    "    tag=next(itag)\n",
    "    bk_genres=[]\n",
    "    for x in bk.find_all(tag,class_='genre-links hidden-phone')[:5]:\n",
    "        bk_genres.append(x.text.replace('\\n',''))\n",
    "        \n",
    "    tag=next(itag)\n",
    "    bk_reviews=[]\n",
    "    for x in bk_titles:\n",
    "        driver.find_element_by_link_text(x).click()\n",
    "        time.sleep(0.8)\n",
    "        current_bk_page=requests.get(driver.current_url)\n",
    "        driver.get(link)\n",
    "        time.sleep(0.8)\n",
    "\n",
    "        current_bk=BeautifulSoup(current_bk_page.content)\n",
    "        bk_reviews.append(current_bk.find(tag,class_='article-body').text.replace('\\n',''))\n",
    "        \n",
    "    df=pd.DataFrame({'Book':bk_titles,'Author':bk_authors,'Genre':bk_genres,'Review':bk_reviews})\n",
    "    df.to_csv('Book_df.csv',index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book</th>\n",
       "      <th>Author</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Special Place for Women</td>\n",
       "      <td>Laura Hankin</td>\n",
       "      <td>Fiction / Satirical Fiction</td>\n",
       "      <td>Laura Hankin’s A Special Place for Women has a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Yeti</td>\n",
       "      <td>Kelly DiPucchio, Claire Keane</td>\n",
       "      <td>Children's / Children's Picture Book</td>\n",
       "      <td>A softhearted, cyan-colored creature, Yeti rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ophie’s Ghosts</td>\n",
       "      <td>Justina Ireland</td>\n",
       "      <td>Children's / Middle Grade</td>\n",
       "      <td>The bestselling author of the young adult nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Plot</td>\n",
       "      <td>Jean Hanff Korelitz</td>\n",
       "      <td>Fiction / Popular Fiction</td>\n",
       "      <td>Not every 350-page novel can be torn through i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Notes on Grief</td>\n",
       "      <td>Chimamanda Ngozi Adichie</td>\n",
       "      <td>Nonfiction / Memoir / Family &amp; Relationships</td>\n",
       "      <td>What is the shape of grief? For writer Chimama...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Book                         Author  \\\n",
       "0  A Special Place for Women                   Laura Hankin   \n",
       "1                   Not Yeti  Kelly DiPucchio, Claire Keane   \n",
       "2             Ophie’s Ghosts                Justina Ireland   \n",
       "3                   The Plot            Jean Hanff Korelitz   \n",
       "4             Notes on Grief       Chimamanda Ngozi Adichie   \n",
       "\n",
       "                                          Genre  \\\n",
       "0                   Fiction / Satirical Fiction   \n",
       "1          Children's / Children's Picture Book   \n",
       "2                     Children's / Middle Grade   \n",
       "3                     Fiction / Popular Fiction   \n",
       "4  Nonfiction / Memoir / Family & Relationships   \n",
       "\n",
       "                                              Review  \n",
       "0  Laura Hankin’s A Special Place for Women has a...  \n",
       "1  A softhearted, cyan-colored creature, Yeti rea...  \n",
       "2  The bestselling author of the young adult nove...  \n",
       "3  Not every 350-page novel can be torn through i...  \n",
       "4  What is the shape of grief? For writer Chimama...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookpage_scraping(bk_link,tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You\n",
    "have to scrape:\n",
    "- Top 10 ODI teams in men’s cricket along with the records for matches, points and\n",
    "rating.\n",
    "- Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "- Top 10 ODI bowlers along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_link='https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "tag='tr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def icc_scraping(link,tag):\n",
    "    icc_page=requests.get(link)\n",
    "    icc_odi=BeautifulSoup(icc_page.content)\n",
    "    \n",
    "    ranks=[]\n",
    "    teams=[]\n",
    "    matches=[]\n",
    "    points=[]\n",
    "    ratings=[]\n",
    "    \n",
    "    ranks.append(int(icc_odi.find(tag,class_='rankings-block__banner').find('td',class_='rankings-block__banner--pos').text))\n",
    "    teams.append(icc_odi.find(tag,class_='rankings-block__banner').find('span',class_='u-hide-phablet').text)\n",
    "    matches.append(int(icc_odi.find(tag,class_='rankings-block__banner').find('td',class_='rankings-block__banner--matches').text))\n",
    "    points.append(icc_odi.find(tag,class_='rankings-block__banner').find('td',class_='rankings-block__banner--points').text)\n",
    "    ratings.append(int(re.sub('[\\n ]','',icc_odi.find(tag,class_='rankings-block__banner').find('td',class_='rankings-block__banner--rating u-text-right').text)))\n",
    "    \n",
    "    for team in icc_odi.find_all(tag,class_='table-body')[:9]:\n",
    "        ranks.append(int(re.split('\\n',team.text)[1]))\n",
    "        teams.append(re.split('\\n',team.text)[4])\n",
    "        matches.append(int(re.split('\\n',team.text)[7]))\n",
    "        points.append(re.split('\\n',team.text)[8])\n",
    "        ratings.append(int(re.split('\\n',team.text)[9]))\n",
    "    \n",
    "    df=pd.DataFrame({'Rank':ranks,'Team':teams,'Matches':matches,'Point':points,'Ratings':ratings})\n",
    "    df.to_csv('MenODI_df.csv',index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Point</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Australia</td>\n",
       "      <td>25</td>\n",
       "      <td>2,945</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>3,344</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,100</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>2,137</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>2,323</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>24</td>\n",
       "      <td>2,157</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>2,222</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>21</td>\n",
       "      <td>1,652</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank          Team  Matches  Point  Ratings\n",
       "0     1   New Zealand       17  2,054      121\n",
       "1     2     Australia       25  2,945      118\n",
       "2     3         India       29  3,344      115\n",
       "3     4       England       27  3,100      115\n",
       "4     5  South Africa       20  2,137      107\n",
       "5     6      Pakistan       24  2,323       97\n",
       "6     7    Bangladesh       24  2,157       90\n",
       "7     8   West Indies       27  2,222       82\n",
       "8     9     Sri Lanka       21  1,652       79\n",
       "9    10   Afghanistan       17  1,054       62"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icc_scraping(icc_link,tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You\n",
    "have to scrape:\n",
    "- Top 10 ODI teams in women’s cricket along with the records for matches, points\n",
    "and rating.\n",
    "- Top 10 women’s ODI players along with the records of their team and rating.\n",
    "- Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wicc_link='https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "tag='tr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wicc_scraping(link,tag):\n",
    "    icc_page=requests.get(link)\n",
    "    icc_odi=BeautifulSoup(icc_page.content)\n",
    "    \n",
    "    ranks=[]\n",
    "    teams=[]\n",
    "    matches=[]\n",
    "    points=[]\n",
    "    ratings=[]\n",
    "    \n",
    "    ranks.append(int(icc_odi.find(tag,class_='rankings-block__banner').find('td',class_='rankings-block__banner--pos').text))\n",
    "    teams.append(icc_odi.find(tag,class_='rankings-block__banner').find('span',class_='u-hide-phablet').text)\n",
    "    matches.append(int(icc_odi.find(tag,class_='rankings-block__banner').find('td',class_='rankings-block__banner--matches').text))\n",
    "    points.append(icc_odi.find(tag,class_='rankings-block__banner').find('td',class_='rankings-block__banner--points').text)\n",
    "    ratings.append(int(re.sub('[\\n ]','',icc_odi.find(tag,class_='rankings-block__banner').find('td',class_='rankings-block__banner--rating u-text-right').text)))\n",
    "    \n",
    "    for team in icc_odi.find_all(tag,class_='table-body')[:9]:\n",
    "        ranks.append(int(re.split('\\n',team.text)[1]))\n",
    "        teams.append(re.split('\\n',team.text)[4])\n",
    "        matches.append(int(re.split('\\n',team.text)[7]))\n",
    "        points.append(re.split('\\n',team.text)[8])\n",
    "        ratings.append(int(re.split('\\n',team.text)[9]))\n",
    "    \n",
    "    df=pd.DataFrame({'Rank':ranks,'Team':teams,'Matches':matches,'Point':points,'Ratings':ratings})\n",
    "    df.to_csv('WomenODI_df.csv',index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Point</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>England</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>1,947</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Indies</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Pakistan</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank          Team  Matches  Point  Ratings\n",
       "0     1     Australia       18  2,955      164\n",
       "1     2  South Africa       24  2,828      118\n",
       "2     3       England       17  1,993      117\n",
       "3     4         India       20  2,226      111\n",
       "4     5   New Zealand       21  1,947       93\n",
       "5     6   West Indies       12  1,025       85\n",
       "6     7      Pakistan       15  1,101       73\n",
       "7     8    Bangladesh        5    306       61\n",
       "8     9     Sri Lanka       11    519       47\n",
       "9    10       Ireland        2     25       13"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wicc_scraping(wicc_link,tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape details of all the mobile phones under Rs. 20,000\n",
    "listed on Amazon.in. The scraped data should include Product Name, Price, Image URL\n",
    "and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_page=requests.get('https://www.amazon.in/s?bbn=1389401031&rh=n%3A1389401031%2Cp_36%3A1318506031&dc&qid=1620500039&rnid=1318502031&ref=lp_1389401031_nr_p_36_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hence Response is not 200 we cannot scrap this page data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping Flipkart data Instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip_link='https://www.flipkart.com/search?sid=tyy%2C4io&otracker=CLP_Filters&p%5B%5D=facets.price_range.from%3DMin&p%5B%5D=facets.price_range.to%3D20000&p%5B%5D=facets.rating%255B%255D%3D4%25E2%2598%2585%2B%2526%2Babove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_scraping(links):\n",
    "    flipkart_page=requests.get(links)\n",
    "    flipkart=BeautifulSoup(flipkart_page.content)\n",
    "    driver=webdriver.Chrome(executable_path='D:\\chromedriver.exe')\n",
    "    driver.get(links)\n",
    "    \n",
    "    mobiles=[]\n",
    "    for x in flipkart.find_all('div',class_='_2kHMtA'):\n",
    "        mobiles.append(x.find('div',class_='_4rR01T').text)\n",
    "        \n",
    "    prices=[]\n",
    "    for x in flipkart.find_all('div',class_='_2kHMtA'):\n",
    "        prices.append(x.find('div',class_='_30jeq3 _1_WHN1').text)\n",
    "        \n",
    "    urls=[]    \n",
    "    for link in driver.find_elements_by_xpath('//div[@class=\"_2kHMtA\"]/a'):\n",
    "        urls.append(link.get_attribute('href'))\n",
    "        \n",
    "    img_srcs=[]\n",
    "    for url in urls:\n",
    "        driver.get(url)\n",
    "        time.sleep(.8)\n",
    "        img_srcs.append(driver.find_element_by_xpath('//div[@class=\"CXW8mj _3nMexc\"]/img').get_attribute('src'))\n",
    "\n",
    "        driver.get(links)\n",
    "        time.sleep(.8)\n",
    "        \n",
    "    df=pd.DataFrame({'Mobile':mobiles,'Price':prices,'Image_URL':urls})\n",
    "    df.to_csv('Flipkart_Mobile.csv',index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mobile</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image_URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realme Narzo 20 (Victory Blue, 64 GB)</td>\n",
       "      <td>₹9,999</td>\n",
       "      <td>https://www.flipkart.com/realme-narzo-20-victo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>realme Narzo 20 (Glory Silver, 64 GB)</td>\n",
       "      <td>₹9,999</td>\n",
       "      <td>https://www.flipkart.com/realme-narzo-20-glory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REDMI 9i (Sea Blue, 64 GB)</td>\n",
       "      <td>₹7,999</td>\n",
       "      <td>https://www.flipkart.com/redmi-9i-sea-blue-64-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>realme Narzo 20 (Glory Silver, 128 GB)</td>\n",
       "      <td>₹10,999</td>\n",
       "      <td>https://www.flipkart.com/realme-narzo-20-victo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realme Narzo 20 (Victory Blue, 128 GB)</td>\n",
       "      <td>₹10,999</td>\n",
       "      <td>https://www.flipkart.com/realme-narzo-20-glory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>realme C21 (Cross Black, 32 GB)</td>\n",
       "      <td>₹7,999</td>\n",
       "      <td>https://www.flipkart.com/poco-m3-cool-blue-64-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>POCO M3 (Cool Blue, 64 GB)</td>\n",
       "      <td>₹10,999</td>\n",
       "      <td>https://www.flipkart.com/realme-narzo-30a-lase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>realme Narzo 30A (Laser Black, 32 GB)</td>\n",
       "      <td>₹8,999</td>\n",
       "      <td>https://www.flipkart.com/realme-narzo-30a-lase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>realme Narzo 30A (Laser Blue, 64 GB)</td>\n",
       "      <td>₹9,999</td>\n",
       "      <td>https://www.flipkart.com/realme-narzo-30a-lase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>realme Narzo 30A (Laser Black, 64 GB)</td>\n",
       "      <td>₹9,999</td>\n",
       "      <td>https://www.flipkart.com/redmi-9i-midnight-bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>REDMI 9i (Midnight Black, 64 GB)</td>\n",
       "      <td>₹7,999</td>\n",
       "      <td>https://www.flipkart.com/realme-c21-cross-blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>POCO M3 (Power Black, 64 GB)</td>\n",
       "      <td>₹10,999</td>\n",
       "      <td>https://www.flipkart.com/realme-c21-cross-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>realme C21 (Cross Blue, 32 GB)</td>\n",
       "      <td>₹7,999</td>\n",
       "      <td>https://www.flipkart.com/poco-m3-power-black-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>POCO M3 (Power Black, 128 GB)</td>\n",
       "      <td>₹11,999</td>\n",
       "      <td>https://www.flipkart.com/realme-c20-cool-blue-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>realme C20 (Cool Blue, 32 GB)</td>\n",
       "      <td>₹6,799</td>\n",
       "      <td>https://www.flipkart.com/realme-c20-cool-grey-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>realme C20 (Cool Grey, 32 GB)</td>\n",
       "      <td>₹6,799</td>\n",
       "      <td>https://www.flipkart.com/redmi-9-power-blazing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>REDMI 9 Power (Blazing Blue, 64 GB)</td>\n",
       "      <td>₹10,499</td>\n",
       "      <td>https://www.flipkart.com/realme-narzo-30a-lase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>realme Narzo 30A (Laser Blue, 32 GB)</td>\n",
       "      <td>₹8,999</td>\n",
       "      <td>https://www.flipkart.com/realme-c12-power-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>realme C12 (Power Silver, 32 GB)</td>\n",
       "      <td>₹7,999</td>\n",
       "      <td>https://www.flipkart.com/realme-c12-power-silv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>realme C12 (Power Blue, 32 GB)</td>\n",
       "      <td>₹7,999</td>\n",
       "      <td>https://www.flipkart.com/realme-c21-cross-blue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>realme C21 (Cross Blue, 64 GB)</td>\n",
       "      <td>₹8,999</td>\n",
       "      <td>https://www.flipkart.com/realme-c25-watery-blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>realme C25 (Watery Blue, 64 GB)</td>\n",
       "      <td>₹9,999</td>\n",
       "      <td>https://www.flipkart.com/poco-m3-cool-blue-128...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>POCO M3 (Cool Blue, 128 GB)</td>\n",
       "      <td>₹11,999</td>\n",
       "      <td>https://www.flipkart.com/poco-m3-power-black-6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OPPO A53 (Mint Cream, 128 GB)</td>\n",
       "      <td>₹12,990</td>\n",
       "      <td>https://www.flipkart.com/redmi-9-power-electri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Mobile    Price  \\\n",
       "0    realme Narzo 20 (Victory Blue, 64 GB)   ₹9,999   \n",
       "1    realme Narzo 20 (Glory Silver, 64 GB)   ₹9,999   \n",
       "2               REDMI 9i (Sea Blue, 64 GB)   ₹7,999   \n",
       "3   realme Narzo 20 (Glory Silver, 128 GB)  ₹10,999   \n",
       "4   realme Narzo 20 (Victory Blue, 128 GB)  ₹10,999   \n",
       "5          realme C21 (Cross Black, 32 GB)   ₹7,999   \n",
       "6               POCO M3 (Cool Blue, 64 GB)  ₹10,999   \n",
       "7    realme Narzo 30A (Laser Black, 32 GB)   ₹8,999   \n",
       "8     realme Narzo 30A (Laser Blue, 64 GB)   ₹9,999   \n",
       "9    realme Narzo 30A (Laser Black, 64 GB)   ₹9,999   \n",
       "10        REDMI 9i (Midnight Black, 64 GB)   ₹7,999   \n",
       "11            POCO M3 (Power Black, 64 GB)  ₹10,999   \n",
       "12          realme C21 (Cross Blue, 32 GB)   ₹7,999   \n",
       "13           POCO M3 (Power Black, 128 GB)  ₹11,999   \n",
       "14           realme C20 (Cool Blue, 32 GB)   ₹6,799   \n",
       "15           realme C20 (Cool Grey, 32 GB)   ₹6,799   \n",
       "16     REDMI 9 Power (Blazing Blue, 64 GB)  ₹10,499   \n",
       "17    realme Narzo 30A (Laser Blue, 32 GB)   ₹8,999   \n",
       "18        realme C12 (Power Silver, 32 GB)   ₹7,999   \n",
       "19          realme C12 (Power Blue, 32 GB)   ₹7,999   \n",
       "20          realme C21 (Cross Blue, 64 GB)   ₹8,999   \n",
       "21         realme C25 (Watery Blue, 64 GB)   ₹9,999   \n",
       "22             POCO M3 (Cool Blue, 128 GB)  ₹11,999   \n",
       "23           OPPO A53 (Mint Cream, 128 GB)  ₹12,990   \n",
       "\n",
       "                                            Image_URL  \n",
       "0   https://www.flipkart.com/realme-narzo-20-victo...  \n",
       "1   https://www.flipkart.com/realme-narzo-20-glory...  \n",
       "2   https://www.flipkart.com/redmi-9i-sea-blue-64-...  \n",
       "3   https://www.flipkart.com/realme-narzo-20-victo...  \n",
       "4   https://www.flipkart.com/realme-narzo-20-glory...  \n",
       "5   https://www.flipkart.com/poco-m3-cool-blue-64-...  \n",
       "6   https://www.flipkart.com/realme-narzo-30a-lase...  \n",
       "7   https://www.flipkart.com/realme-narzo-30a-lase...  \n",
       "8   https://www.flipkart.com/realme-narzo-30a-lase...  \n",
       "9   https://www.flipkart.com/redmi-9i-midnight-bla...  \n",
       "10  https://www.flipkart.com/realme-c21-cross-blac...  \n",
       "11  https://www.flipkart.com/realme-c21-cross-blue...  \n",
       "12  https://www.flipkart.com/poco-m3-power-black-1...  \n",
       "13  https://www.flipkart.com/realme-c20-cool-blue-...  \n",
       "14  https://www.flipkart.com/realme-c20-cool-grey-...  \n",
       "15  https://www.flipkart.com/redmi-9-power-blazing...  \n",
       "16  https://www.flipkart.com/realme-narzo-30a-lase...  \n",
       "17  https://www.flipkart.com/realme-c12-power-blue...  \n",
       "18  https://www.flipkart.com/realme-c12-power-silv...  \n",
       "19  https://www.flipkart.com/realme-c21-cross-blue...  \n",
       "20  https://www.flipkart.com/realme-c25-watery-blu...  \n",
       "21  https://www.flipkart.com/poco-m3-cool-blue-128...  \n",
       "22  https://www.flipkart.com/poco-m3-power-black-6...  \n",
       "23  https://www.flipkart.com/redmi-9-power-electri...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipkart_scraping(flip_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to extract information about the local weather from the National\n",
    "Weather Service website of USA, https://www.weather.gov/ for the city, San\n",
    "Francisco. You need to extract data about 7 day extended forecast display for the city.\n",
    "The data should include period, short description, temperature and description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_link='https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YJep3bUzZPY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_scraping(link):\n",
    "    wheather_page=requests.get(link)\n",
    "    wheather=BeautifulSoup(wheather_page.content)\n",
    "    \n",
    "    periods=[]\n",
    "    temps=[]\n",
    "    \n",
    "    for x in wheather.find_all('li',class_='forecast-tombstone')[:7]:\n",
    "        periods.append(x.find('p').text)\n",
    "        try:\n",
    "            temps.append(x.find('p',class_='temp temp-low').text)\n",
    "        except:\n",
    "            temps.append(x.find('p',class_='temp temp-high').text)\n",
    "            \n",
    "    decps=[]\n",
    "    for x in wheather.find_all('div',class_='row row-odd row-forecast'):\n",
    "        decps.append(x.find('div',class_='col-sm-10 forecast-text').text)\n",
    "        \n",
    "    df=pd.DataFrame({'Period':periods,'Temperature':temps,'Description':decps})\n",
    "    df.to_csv('Whether_San-Francisco.csv',index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today</td>\n",
       "      <td>High: 61 °F</td>\n",
       "      <td>Mostly cloudy, then gradually becoming sunny, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Low: 50 °F</td>\n",
       "      <td>Mostly cloudy, then gradually becoming sunny, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Friday</td>\n",
       "      <td>High: 63 °F</td>\n",
       "      <td>Mostly sunny, with a high near 65. Southwest w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FridayNight</td>\n",
       "      <td>Low: 51 °F</td>\n",
       "      <td>Sunny, with a high near 64.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>High: 65 °F</td>\n",
       "      <td>Partly sunny, with a high near 62.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SaturdayNight</td>\n",
       "      <td>Low: 52 °F</td>\n",
       "      <td>Mostly sunny, with a high near 65.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>High: 64 °F</td>\n",
       "      <td>Sunny, with a high near 67.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Period  Temperature  \\\n",
       "0          Today  High: 61 °F   \n",
       "1        Tonight   Low: 50 °F   \n",
       "2         Friday  High: 63 °F   \n",
       "3    FridayNight   Low: 51 °F   \n",
       "4       Saturday  High: 65 °F   \n",
       "5  SaturdayNight   Low: 52 °F   \n",
       "6         Sunday  High: 64 °F   \n",
       "\n",
       "                                         Description  \n",
       "0  Mostly cloudy, then gradually becoming sunny, ...  \n",
       "1  Mostly cloudy, then gradually becoming sunny, ...  \n",
       "2  Mostly sunny, with a high near 65. Southwest w...  \n",
       "3                        Sunny, with a high near 64.  \n",
       "4                 Partly sunny, with a high near 62.  \n",
       "5                 Mostly sunny, with a high near 65.  \n",
       "6                        Sunny, with a high near 67.  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_scraping(weather_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
